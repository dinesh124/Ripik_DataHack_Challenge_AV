{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cee973",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2568a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n",
      "Unfreezing layer 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|████████████████████████████████████████| 875/875 [05:29<00:00,  2.65it/s, Loss=0.0375, Accuracy=0.939]\n",
      "Epoch 2/5: 100%|█████████████████████████████████████████| 875/875 [05:24<00:00,  2.69it/s, Loss=0.163, Accuracy=0.943]\n",
      "Epoch 3/5: 100%|█████████████████████████████████████████| 875/875 [05:28<00:00,  2.67it/s, Loss=0.137, Accuracy=0.947]\n",
      "Epoch 4/5: 100%|██████████████████████████████████████████| 875/875 [05:29<00:00,  2.66it/s, Loss=0.146, Accuracy=0.95]\n",
      "Epoch 5/5: 100%|████████████████████████████████████████| 875/875 [05:31<00:00,  2.64it/s, Loss=0.0213, Accuracy=0.952]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfreezing layer 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|█████████████████████████████████████████| 875/875 [05:36<00:00,  2.60it/s, Loss=0.144, Accuracy=0.967]\n",
      "Epoch 2/5: 100%|█████████████████████████████████████████| 875/875 [05:36<00:00,  2.60it/s, Loss=0.309, Accuracy=0.968]\n",
      "Epoch 3/5: 100%|█████████████████████████████████████████| 875/875 [05:43<00:00,  2.55it/s, Loss=0.0456, Accuracy=0.97]\n",
      "Epoch 4/5: 100%|██████████████████████████████████████████| 875/875 [05:49<00:00,  2.50it/s, Loss=0.61, Accuracy=0.972]\n",
      "Epoch 5/5: 100%|████████████████████████████████████████| 875/875 [05:56<00:00,  2.45it/s, Loss=0.0198, Accuracy=0.974]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define constants and paths\n",
    "IMG_SIZE = 244\n",
    "device = torch.device(\"cuda\")\n",
    "image_folder = 'D:/DATA/augmented_images'\n",
    "val_df = pd.read_csv('df_test.csv')\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Custom dataset class\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, transform=None):\n",
    "        self.df = df\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def load_image(self, img_path):\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        img = img.resize((IMG_SIZE, IMG_SIZE))\n",
    "        return img\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fname = self.df.loc[idx, 'filename']\n",
    "        label = self.df.loc[idx, 'label']\n",
    "        img_path = os.path.join(self.img_dir, fname)\n",
    "        img = self.load_image(img_path)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)  # Convert PIL to Tensor\n",
    "        return img, label\n",
    "\n",
    "# Instantiate EfficientNet B0 model\n",
    "model = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "model.to(device)\n",
    "\n",
    "# Load augmented checkpoint\n",
    "checkpoint_aug = torch.load('FineTunedmodel_checkpoint_1_5.pth')\n",
    "model.load_state_dict(checkpoint_aug['model_state_dict'])\n",
    "\n",
    "# Freeze early layers\n",
    "for param in list(model.parameters())[:5]:\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Small LR for fine-tuning\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "# DataLoader for validation set using your custom dataset\n",
    "val_transform = transforms.Compose([transforms.ToTensor()])\n",
    "val_ds = ImageDataset(val_df, 'D:/DATA/augmented_images', transform=val_transform)\n",
    "val_dl = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Set up early stopping\n",
    "early_stopping_counter = 0\n",
    "patience = 3  # Set your patience value\n",
    "best_val_loss = float('inf')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "PATH = 'C:/Users/Sri Ram/Untitled Folder 8/FineTunedmodel_checkpoint_1_5.pth'\n",
    "\n",
    "# Unfreeze layers gradually\n",
    "for i in range(2):\n",
    "    layer_i = list(model.children())[i]\n",
    "    for param in layer_i.parameters():\n",
    "        param.requires_grad = True\n",
    "    lr = (i+1) * 1e-5\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    print(\"Unfreezing layer\", i + 1)\n",
    "\n",
    "    # Fine-tune\n",
    "    true_labels, predicted_labels = [], []\n",
    "    for epoch in range(5):\n",
    "        model.train()  # Set the model to training mode\n",
    "        tqdm_val_dl = tqdm(val_dl, desc=f'Epoch {epoch + 1}/{5}')\n",
    "\n",
    "        for x, y in tqdm_val_dl:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(x)\n",
    "            loss = criterion(pred, y)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            true_labels.extend(y.cpu().numpy())\n",
    "            predicted_labels.extend(torch.argmax(pred, dim=1).cpu().numpy())\n",
    "            accuracy_val = accuracy_score(true_labels, predicted_labels)\n",
    "\n",
    "            tqdm_val_dl.set_postfix({'Loss': loss.item(), 'Accuracy': accuracy_val})\n",
    "    \n",
    "\n",
    "        tqdm_val_dl.close()\n",
    "\n",
    "\n",
    "    # Save fine-tuned model\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss.item(),\n",
    "        'accuracy': accuracy_val\n",
    "    }, PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91fcb41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
